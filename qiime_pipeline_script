###QIIME META_ANALYSIS PIPELINE
#I will be applying this pipeine to each individual dataset until merging them
#...at the end


#IMPORTING
#the data for this project are both .fasta and .fastq
#import demultiplexed fastq seqs w/ quality scores
qiime tools import
--type 'SampleData[PairedEndSequencesWithQuality]'
--input-path [manifest_file_path] #see evernote on how to make manifest
--output-path [data.qza]
--input-format PairedEndFastqManifestPhred33V2

#import .fasta seqs
qiime tools import
--input-path [data]
--output-path [data.qza]
--type 'SampleData[Sequences]'
#-----end-import----#


## VISUALIZING
# Tabuluting is the main method of visualizing aross steps in the process
qiime feature-table tabulate
--i-table table.qza
--o-visualization table.qzv
--m-sample-metadata-file metadata.tsv
#-----end-visualization----#


#DEREP/DENOISE SEQUENCES
#denoise and derep .fastq seqs w/ uniform length
qiime dada2 denoise-paired
--i-demultiplexed-seqs [demux_seqs.qza]
--p-trunc-len-f 0 #use demux_seqs.qzv to get number
--p-trunc-len-r 0 #use demux visualization to get number
--o-representative-sequences [rep_seqs.qza]
--o-table [table.qza]
--o-denoising-stats [dadastats.qza]

#deblur method of denoising/derep
qiime deblur denoise-16S
--i-demultiplexed-seqs [demux_seqs.qza]
--p-trim-length -1 #-1 disables the trim feature
--o-table [table.qza]
--o-representative-sequences [rep_seqs.qza]
--o-stats [deblur_stats.qza]

#dereping .fasta files
qiime vsearch dereplicate-sequences
 --i-sequences [seqs.qza]
 --o-dereplicated-table [derep_table.qza]
 --o-dereplicated-sequences [derep_seqs.qza]
#-----end-derep/denoise----#


#FILTERING DATA.1
#Use this step only for fasta data
#Filter Low-FQ Features
qiime feature-table filter-features
--i-table [derep_table].qza
--p-min-frequency 7 #ARBITRARY NUMBER could go higher or lower
--o-filtered-table [feat_fq7_table.qza]

#Contigency Filtering
qiime feature-table filter-features
--i-table [x_filtered_table.qza]
--p-min-samples 2
--o-filtered-table [x_c2_table.qza]

#Filter Seqs based on Tables
qiime feature-table filter-seqs
--i-table [x_table.qza]
--i-data [derep_seqs.qza]
--o-filtered-data [x_seqs.qza]

#Filter samples based on Metadata
#(summarize table with --m-sample-metadata-file to see if it's required)
qiime feature-table filter-samples
--i-table [x_table.qza]
--m-metadata-file [mapping.txt]
--p-no-exclude-ids
--o-filtered-table [x_meta_filtered_table.qza]
#-----end-filtering----#


#CLUSTER/FILTER DATA
#Filter Seqs based on Tables
qiime feature-table filter-seqs
--i-table [x_table.qza]
--i-data [derep_seqs.qza]
--o-filtered-data [x_seqs.qza]

#Clustering OTU's
#Cluster at 97%
qiime vsearch cluter-features-de-novo
--i-table [derep_table.qza]
--i-sequences [derep_seqs.qza]
--o-clustered-table [97_denovo_table.qza]
--o-clustered-sequences [97_denovo_seqs.qza]
--p-perc-identity 0.97
#-----end-cluster/filter----#


#MERGE DATASETS
qiime feature-table merge
--i-tables [x1_table.qza]
--i-tables [x2_table.qza]
--p-overlap-method 'sum'
--o-merged-table [meta_merged_table.qza]

#move meta_seqs.fasta from local drive
#import .fasta seqs
qiime tools import
--input-path [data]
--output-path [data.qza]
--type 'FeatureData[Sequence]'

#Filter Seqs based on Tables
qiime feature-table filter-seqs
--i-table [x_table.qza]
--i-data [derep_seqs.qza]
--o-filtered-data [x_seqs.qza]
#-----end-merge----#


#ASSIGN TAXONMY#
#used greeengenes 99% to assign taxa
qiime tools import
--input-path [99_otus.fasta]
--output-path [ref_seqs.qza]
--type 'FeatureData[Sequence]'

#extract the reference reads corresponding with the primers
qiime feature-classifier extract-reads
--i-sequences [ref_seqs.qza]
--p-f-primer CCTACGGGNGGCWGCAG
--p-r-primer GACTACHVGGGTATCTAATCC #got primers form mapping_file.txt
--p-min-length 250 #min-length based on the length of half reads
--p-max-length 466
--o-reads [extracted_ref_seqs.qza]

#upload the corresponding taxonomy
qiime tools import
--type 'FeatureData[Taxonomy]'
--input-format HeaderlessTSVTaxonomyFormat
--input-path [taxonomy.txt]
--output-path [ref_tax.qza]

#train the classifier
qiime feature-classifier fit-classifier-naive-bayes
--i-reference-reads [extracted_ref_seqs.qza]
--i-reference-taxonomy [ref_tax.qza]
--o-classifier [classifier.qza]

#apply the classifier to the actual dataset
#used same classifier on all datasets since primers are the same
qiime feature-classifier classify-sklearn
--i-classifier [classifier.qza]
--i-reads[rep_seqs.qza]
--o-classification [taxonomy.qza]

#Taxonomic Filtering.1
#(use in the event that there are features that aren't assigned)
qiime feature-table filter-features
--i-table [x_table.qza]
--i-data [x_taxonomy.qza]
--o-filtered-data [id-filt_table.qza]

#Taxonomic Filtering.2
qiime taxa filter-table
--i-table [x_filtered_table.qza]
--i-taxonomy [taxonomy.qza]
--p-include p_
--o-filtered-table [x_phyla.qza]

#Filter Seqs based on Tables
qiime feature-table filter-seqs
--i-table [x_table.qza]
--i-data [derep_seqs.qza]
--o-filtered-data [x_seqs.qza]
#---end-taxonomy---#


#FILTERING DATA.2
#Use this step to filter all datasets after merging
#Contigency Filtering
qiime feature-table filter-features
--i-table [x_filtered_table.qza]
--p-min-samples 2
--o-filtered-table [x_c2_table.qza]

#Filter Seqs based on Tables
qiime feature-table filter-seqs
--i-table [x_table.qza]
--i-data [derep_seqs.qza]
--o-filtered-data [x_seqs.qza]
#-----end-filtering----#

#DIVERSITY ANALYSIS
#create a rooted phylogenetic tree
qiime phylogeny align-to-tree-mafft-fasttree
--i-sequences [x_rep_seqs.qza]
--o-alignment [x_align_seqs.qza]
--o-masked-alignment [x_mskd_align_seqs.qza]
--o-tree [x_tree.qza]
--o-rooted-tree [x_rootd.qza]

#phylogenetic beta diversity
qiime diversity core-metrics-phylogentic
--i-phylogeny [rooted_tree.qza]
--i-table [table.qza]
--p-sampling-depth x #look at feature_table.qzv to determine sampling depth
--m-metadata-file [metadata.txt]
--output-dir core-metrics-results
#-----END-QIIME-ANALYSIS-----#
